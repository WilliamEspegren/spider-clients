# spider-clients

Welcome to the **spider-clients** repository, the ultimate destination for integrating the fastest and most efficient web crawler, **Spider**, into your projects. Here, you can find client libraries that facilitate the use of [Spider Cloud](https://spider.cloud) services from various programming environments. Jumpstart your web crawling and data indexing tasks with our seamless, high-performance solutions.

## Python

Leverage the power of Spider in your Python applications. Navigate to our [Python client library directory](./python/) for installation instructions, usage guides, and examples. Get ready to supercharge your data extraction tasks with the efficiency and speed of Spider, all from within your Python environment.

## Javascript

Integrate Spider effortlessly into your Javascript projects. Visit our [Javascript client library directory](./javascript/) to explore how you can utilize Spider in Node.js or browser environments. Enhance your web scraping capabilities, improve data collection strategies, and unlock new possibilities with our cutting-edge technology.

---

### Features

- **Concurrent Crawling:** Maximize your data extraction efficiency with Spider's advanced concurrency models.
- **Streaming:** Stream crawled data in real-time, ensuring timely processing and analysis.
- **Headless Chrome Rendering:** Capture JavaScript-rendered page contents with ease.
- **HTTP Proxies Support:** Navigate through the web anonymously and bypass content restrictions.
- **Cron Jobs:** Schedule your crawling tasks to run automatically, saving time and resources.
- **Smart Mode:** Automate crawling tasks with AI-driven strategies for smarter data collection.
- **Blacklisting, Whitelisting, and Budgeting Depth:** Fine-tune your crawls to focus on relevant data and manage resource utilization.
- **Dynamic AI Prompt Scripting Headless:** Leverage AI to script dynamic interactions with web pages, simulating real user behavior.

### Getting Started

Dive into the world of high-speed web crawling with Spider. Whether you're looking to deploy Spider locally or utilize our hosted services, we've got you covered. Start by exploring our client libraries above, or visit the main [Spider repository](https://github.com/spider-rs/spider) for comprehensive documentation, installation guides, and more.

#### Supabase

Both clients allow you to optionally install [Supabase](https://supabase.com/docs/reference) and use the client underneath to utilize custom queries and more. You can log in and perform all actions on your account with the client. Some features may be limited or rate-limited.

### Support & Contribution

Your feedback and contributions are highly valued. Should you encounter any issues or have suggestions for improvements, please feel free to open an issue or submit a pull request. Visit our [Contributing Guidelines](https://github.com/spider-rs/spider/blob/master/CONTRIBUTING.md) for more information on how you can contribute to the Spider project.

We're on a mission to make web crawling faster, smarter, and more accessible than ever before. Join us in redefining the boundaries of data extraction and indexing with **Spider**.
